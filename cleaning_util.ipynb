{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562775f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def common_var_checker(df_train, df_val, df_test, target):\n",
    "    # Get the dataframe of common variables between the training, validation and test data\n",
    "    df_common_var = pd.DataFrame(np.intersect1d(np.intersect1d(df_train.columns, df_val.columns), np.union1d(df_test.columns, [target])),\n",
    "                                 columns=['common var'])\n",
    "\n",
    "    return df_common_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_checker(df, dtype='float'):\n",
    "    # Get the dataframe of identifiers\n",
    "    df_id = df[[var for var in df.columns\n",
    "                # If the data type is not dtype\n",
    "                if (df[var].dtype != dtype\n",
    "                    # If the value is unique for each sample\n",
    "                    and df[var].nunique(dropna=True) == df[var].notnull().sum())]]\n",
    "\n",
    "    return df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7251dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_transformer(df, datetime_vars):\n",
    "    # The dictionary with key as datetime type and value as datetime type operator\n",
    "    dict_ = {'year': lambda x: x.dt.year,\n",
    "             'month': lambda x: x.dt.month,\n",
    "             'day': lambda x: x.dt.day,\n",
    "             'hour': lambda x: x.dt.hour,\n",
    "             'minute': lambda x: x.dt.minute,\n",
    "             'second': lambda x: x.dt.second}\n",
    "\n",
    "    # Make a copy of df\n",
    "    df_datetime = df.copy(deep=True)\n",
    "\n",
    "    # For each variable in datetime_vars\n",
    "    for var in datetime_vars:\n",
    "        # Cast the variable to datetime\n",
    "        df_datetime[var] = pd.to_datetime(df_datetime[var])\n",
    "\n",
    "        # For each item (datetime_type and datetime_type_operator) in dict_\n",
    "        for datetime_type, datetime_type_operator in dict_.items():\n",
    "            # Add a new variable to df_datetime where:\n",
    "            # the variable's name is var + '_' + datetime_type\n",
    "            # the variable's values are the ones obtained by datetime_type_operator\n",
    "            df_datetime[var + '_' +\n",
    "                        datetime_type] = datetime_type_operator(df_datetime[var])\n",
    "\n",
    "    # Remove datetime_vars from df_datetime\n",
    "    df_datetime = df_datetime.drop(columns=datetime_vars)\n",
    "\n",
    "    return df_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7214c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_checker(df):\n",
    "    # Get the dataframe of variables with NaN, their proportion of NaN and data type\n",
    "    df_nan = pd.DataFrame([[var, df[var].isna().sum() / df.shape[0], df[var].dtype]\n",
    "                           for var in df.columns if df[var].isna().sum() > 0],\n",
    "                          columns=['var', 'proportion', 'dtype'])\n",
    "\n",
    "    # Sort df_nan in accending order of the proportion of NaN\n",
    "    df_nan = df_nan.sort_values(\n",
    "        by='proportion', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64776fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_var_checker(df, dtype='object'):\n",
    "    # Get the dataframe of categorical variables and their number of unique value\n",
    "    df_cat = pd.DataFrame([[var, df[var].nunique(dropna=False)]\n",
    "                           # If the data type is dtype\n",
    "                           for var in df.columns if df[var].dtype == dtype],\n",
    "                          columns=['var', 'nunique'])\n",
    "\n",
    "    # Sort df_cat in accending order of the number of unique value\n",
    "    df_cat = df_cat.sort_values(\n",
    "        by='nunique', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    return df_cat"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
